{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'admin': {'log-format': '%(name)s - %(levelname)s - %(message)s',\n",
      "           'log-length': 10000,\n",
      "           'max-error-length': 10000,\n",
      "           'pdb-on-err': False,\n",
      "           'tick': {'interval': '20ms', 'limit': 3000}},\n",
      " 'client': {'heartbeat': '5s'},\n",
      " 'comm': {'compression': 'auto',\n",
      "          'default-scheme': 'tcp',\n",
      "          'offload': '10MiB',\n",
      "          'recent-messages-log-length': 0,\n",
      "          'require-encryption': False,\n",
      "          'retry': {'count': 0, 'delay': {'max': '20s', 'min': '1s'}},\n",
      "          'socket-backlog': 2048,\n",
      "          'timeouts': {'connect': '5s', 'tcp': '30s'},\n",
      "          'tls': {'ca-file': None,\n",
      "                  'ciphers': None,\n",
      "                  'client': {'cert': None, 'key': None},\n",
      "                  'scheduler': {'cert': None, 'key': None},\n",
      "                  'worker': {'cert': None, 'key': None}},\n",
      "          'zstd': {'level': 3, 'threads': 0}},\n",
      " 'dashboard': {'export-tool': False, 'link': 'http://{host}:{port}/status'},\n",
      " 'deploy': {'lost-worker-timeout': '15s'},\n",
      " 'scheduler': {'allowed-failures': 3,\n",
      "               'bandwidth': 100000000,\n",
      "               'blocked-handlers': [],\n",
      "               'dashboard': {'status': {'task-stream-length': 1000},\n",
      "                             'tasks': {'task-stream-length': 100000},\n",
      "                             'tls': {'ca-file': None,\n",
      "                                     'cert': None,\n",
      "                                     'key': None}},\n",
      "               'default-data-size': 1000,\n",
      "               'default-task-durations': {},\n",
      "               'events-cleanup-delay': '1h',\n",
      "               'idle-timeout': None,\n",
      "               'pickle': True,\n",
      "               'preload': [],\n",
      "               'preload-argv': [],\n",
      "               'transition-log-length': 100000,\n",
      "               'validate': False,\n",
      "               'work-stealing': True,\n",
      "               'worker-ttl': None},\n",
      " 'version': 2,\n",
      " 'worker': {'blocked-handlers': [],\n",
      "            'connections': {'incoming': 10, 'outgoing': 50},\n",
      "            'daemon': True,\n",
      "            'lifetime': {'duration': None,\n",
      "                         'restart': False,\n",
      "                         'stagger': '0 seconds'},\n",
      "            'memory': {'pause': 0.7,\n",
      "                       'spill': False,\n",
      "                       'target': False,\n",
      "                       'terminate': 0.95},\n",
      "            'multiprocessing-method': 'forkserver',\n",
      "            'preload': [],\n",
      "            'preload-argv': [],\n",
      "            'profile': {'cycle': '1000ms',\n",
      "                        'interval': '10ms',\n",
      "                        'low-level': False},\n",
      "            'use-file-locking': True,\n",
      "            'validate': False}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/groups/scicompsoft/home/bennettd/miniconda3/lib/python3.7/site-packages/distributed/dashboard/core.py:72: UserWarning: \n",
      "Port 8787 is already in use. \n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the diagnostics dashboard on a random port instead.\n",
      "  warnings.warn(\"\\n\" + msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "static: http://10.36.111.12:8787/status\n",
      "adaptive http://10.36.111.12:46139/status\n"
     ]
    }
   ],
   "source": [
    "from distributed import Client\n",
    "import dask.array as da\n",
    "import os\n",
    "import dask\n",
    "from dask_jobqueue import LSFCluster\n",
    "import pprint\n",
    "\n",
    "# ensure that the lsf launch script works properly\n",
    "dask.config.set({\"jobqueue.lsf.use-stdin\": True})\n",
    "# configure worker behavior as per matt rocklin's suggestion \n",
    "dask.config.set({\"distributed.worker.memory.target\" : False,\n",
    "                 \"distributed.worker.memory.spill\": False, \n",
    "                 \"distributed.worker.memory.pause\" : 0.70 ,\n",
    "                 \"distributed.worker.memory.terminate\" : 0.95})\n",
    "\n",
    "pprint.pprint(dask.config.get('distributed'))\n",
    "\n",
    "def get_jobqueue_cluster(\n",
    "    walltime=\"1:00\",\n",
    "    ncpus=1,\n",
    "    cores=1,\n",
    "    local_directory=None,\n",
    "    memory=\"16GB\",\n",
    "    env_extra='single-threaded',\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Instantiate a dask_jobqueue cluster using the LSF scheduler on the Janelia Research Campus compute cluster.\n",
    "    This function wraps the class dask_jobqueue.LSFCLuster and instantiates this class with some sensible defaults.\n",
    "    Extra kwargs added to this function will be passed to LSFCluster().\n",
    "    The full API for the LSFCluster object can be found here:\n",
    "    https://jobqueue.dask.org/en/latest/generated/dask_jobqueue.LSFCluster.html#dask_jobqueue.LSFCluster\n",
    "    \"\"\"\n",
    "\n",
    "    if env_extra == 'single-threaded':\n",
    "        env_extra = [\n",
    "            \"export NUM_MKL_THREADS=1\",\n",
    "            \"export OPENBLAS_NUM_THREADS=1\",\n",
    "            \"export OPENMP_NUM_THREADS=1\",\n",
    "            \"export OMP_NUM_THREADS=1\",\n",
    "        ]\n",
    "\n",
    "    if local_directory is None:\n",
    "        local_directory = \"/scratch/\" + os.environ[\"USER\"] + \"/\"\n",
    "\n",
    "    cluster = LSFCluster(\n",
    "        queue=\"normal\",\n",
    "        walltime=walltime,\n",
    "        cores=cores,\n",
    "        ncpus=ncpus,\n",
    "        local_directory=local_directory,\n",
    "        memory=memory,\n",
    "        env_extra=env_extra,\n",
    "        job_extra=[\"-o /dev/null\"],\n",
    "        **kwargs\n",
    "    )\n",
    "    return cluster\n",
    "\n",
    "# create static and adaptive cluster\n",
    "\n",
    "client_static, client_adaptive = Client(get_jobqueue_cluster()), Client(get_jobqueue_cluster())\n",
    "floor = 10\n",
    "client_static.cluster.scale(floor)\n",
    "client_adaptive.cluster.adapt(minimum_jobs=floor)\n",
    "\n",
    "print(f'static: {client_static.cluster.dashboard_link}\\nadaptive {client_adaptive.cluster.dashboard_link}') \n",
    "\n",
    "shape = (11087, 2500, 10000) # based on my actual data\n",
    "dtype = 'uint16' \n",
    "chunks_easy = (40, 1024, 1024)\n",
    "chunks_hard = (1, 1024, 1024) \n",
    "dummy_easy = da.zeros(shape=shape, chunks=chunks_easy, dtype=dtype)\n",
    "dummy_hard = da.zeros(shape=shape, chunks=chunks_hard, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_easy = dummy_easy\n",
    "# even the static cluster chokes if I use the entire dataset with tiny chunks, so for the hard sample\n",
    "# I only take the first 1000 elements of the data\n",
    "sample_hard = dummy_hard[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.4 s, sys: 1.92 s, total: 1min\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = client_static.compute([sample_easy.min(), sample_easy.max()], sync=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 18s, sys: 2.77 s, total: 1min 21s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = client_static.compute([sample_hard.min(), sample_hard.max()], sync=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptive cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.1 s, sys: 2.17 s, total: 40.3 s\n",
      "Wall time: 42.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = client_adaptive.compute([sample_easy.min(0), sample_easy.max(0)], sync=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KilledWorker",
     "evalue": "(\"('zeros-getitem-8c2e645ab441159d64b8ad576aa516f2', 245, 0, 9)\", <Worker 'tcp://10.36.111.34:39592', memory: 0, processing: 95>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKilledWorker\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, collections, sync, optimize_graph, workers, allow_other_workers, resources, retries, priority, fifo_timeout, actors, traverse, **kwargs)\u001b[0m\n\u001b[1;32m   2779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2780\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2781\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2782\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2783\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   1872\u001b[0m                 \u001b[0mdirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1873\u001b[0m                 \u001b[0mlocal_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1874\u001b[0;31m                 \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1875\u001b[0m             )\n\u001b[1;32m   1876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             return sync(\n\u001b[0;32m--> 769\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m             )\n\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallback_timeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                 \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tornado/gen.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                         \u001b[0mexc_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36m_gather\u001b[0;34m(self, futures, errors, direct, local_worker)\u001b[0m\n\u001b[1;32m   1728\u001b[0m                             \u001b[0mexc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1730\u001b[0;31m                             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1731\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1732\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"skip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKilledWorker\u001b[0m: (\"('zeros-getitem-8c2e645ab441159d64b8ad576aa516f2', 245, 0, 9)\", <Worker 'tcp://10.36.111.34:39592', memory: 0, processing: 95>)"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# dashboard is unresponsive, a lot of worker-errors are reported, and this never completes.\n",
    "# killing execution with a keyboard interrupt doesn't stop zombie tasks from running on workers.\n",
    "result = client_adaptive.compute([sample_hard.min(0), sample_hard.max(0)], sync=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
